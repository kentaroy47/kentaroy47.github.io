![Datasetculling](https://github.com/kentaroy47/kentaroy47.github.io/blob/master/images/dataset.PNG)

---
title: "Dataset Culling: Towards Efficient Training Of Distillation-Based Domain Specific Models"
collection: publications
permalink: /publication/Dataset Culling
excerpt: 'We propose Dataset Culling: a pipeline to reduce the size of the dataset for training.'
date: 2019-02-01
venue: 'IEEE ICIP 2019'
paperurl: 'http://academicpages.github.io/files/paper1.pdf'
citation: 'Yoshioka, Kentaro. (2019). &quot;Dataset Culling: Towards Efficient Training Of Distillation-Based Domain Specific Models.&quot; <i>IEEE ICIP</i>. 1(1).'
---

Dataset Culling filters out images that are easy to classify since they contribute little to improving the accuracy. The difficulty is measured using our proposed confidence loss metric with little computational overhead. We show that the dataset size can be culled by a factor of 300× to reduce the total training time by 47× with no accuracy loss or even with slight improvement.

[Download paper here](https://arxiv.org/abs/1902.00173)

[Codes](https://github.com/kentaroy47/DatasetCulling)

